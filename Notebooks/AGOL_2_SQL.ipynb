{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "## Script: AGOL_2_SQL.py\n",
    "## Author: Jeremy Mullins, Derek Morgan\n",
    "## Date:\n",
    "##\n",
    "## Description:\n",
    "##        This script is the test script for importing a AGOL feature layer into MS SQL as a table.\n",
    "##\n",
    "## Required prerequisites:\n",
    "##        - ArcGIS API for Python\n",
    "##            (https://developers.arcgis.com/python/)\n",
    "##\n",
    "##        - pyodbc Module\n",
    "##            (https://github.com/mkleehammer/pyodbc)\n",
    "##                to install after download, open Python command prompt and type the following:\n",
    "##                    -- conda install pyodbc  --\n",
    "##\n",
    "##        - MS ODBC Driver for SQL Server (v17)\n",
    "##            (https://docs.microsoft.com/en-us/sql/connect/odbc/download-odbc-driver-for-sql-server?view=sql-server-2017)\n",
    "##\n",
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary modules\n",
    "from arcgis.gis import GIS\n",
    "import pyodbc as sql\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import zipfile\n",
    "import arcpy\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config_jdm.ini')\n",
    "\n",
    "# assign config variables\n",
    "workSPACE = config['SCRIPT']['workSPACE']\n",
    "agolURL = config['AGOL']['URL']\n",
    "agolUSER = config['AGOL']['USER']\n",
    "agolPW = config['AGOL']['PW']\n",
    "iD = config['SCRIPT']['itemID']\n",
    "csvTITLE = config['SCRIPT']['csvTITLE']\n",
    "csvLOC = config['SCRIPT']['csvOUTPUT']\n",
    "zipLOC = config['SCRIPT']['zipLOC']\n",
    "sqlDRVR = config['SQL']['odbcDRVR']\n",
    "sqlSERV = config['SQL']['SERVER']\n",
    "sqlDB = config['SQL']['DB']\n",
    "sqlUSER = config['SQL']['USER']\n",
    "sqlPW = config['SQL']['PW']\n",
    "createTABLE = config['SQL']['createTEMP']\n",
    "csvINSERT = config['SQL']['csvINSERT']\n",
    "insNewRows = config['SQL']['updateTABLE']\n",
    "delTEMP = config['SQL']['delTEMP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set workspace(s)\n",
    "arcpy.env.workspace = workSPACE\n",
    "os.chdir(workSPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign into AGOL account\n",
    "gis = GIS(agolURL, agolUSER, agolPW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature layer in question\n",
    "featureLayer = gis.content.get(iD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Data/PhD/Projects/SRC/src/Notebooks\\\\test.zip'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export feature layer into CSV and save locally as ZIP file\n",
    "output_file = featureLayer.export(title=csvTITLE,\n",
    "                                   export_format=\"CSV\")\n",
    "output_file.download(csvLOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip downloaded feature layer data\n",
    "zip_ref = zipfile.ZipFile(zipLOC, 'r')\n",
    "zip_ref.extractall(csvLOC)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove excess files\n",
    "os.remove(zipLOC)\n",
    "output_file.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CSV into SQL database as view\n",
    "conn = sql.connect('Driver='+sqlDRVR+';'\n",
    "                      'Server='+sqlSERV+';'\n",
    "                      'Database='+sqlDB+';'\n",
    "                      'trusted_connection=yes;'\n",
    "                      'UID='+sqlUSER+';'\n",
    "                      'PWD='+sqlPW+';')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#https://datatofish.com/how-to-connect-python-to-sql-server-using-pyodbc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CSV into pandas and fill any NaN with '000'\n",
    "df = pd.read_csv('Buildings_0.csv')\n",
    "df.fillna('000',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates temporary table\n",
    "cursor.execute('CREATE TABLE [dbo].[src_temp]([OBJECTID] INT, '\n",
    "               '[BuildingIdent] varchar(100), '\n",
    "               '[Description] varchar(50), '\n",
    "               '[Class] varchar(3), '\n",
    "               '[TypeCode] INT, ' \n",
    "               '[GlobalID] varchar(50))')\n",
    "cursor.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserts rows from CSV\n",
    "for index,row in df.iterrows():\n",
    "    cursor.execute('INSERT INTO [dbo].[src_temp]([OBJECTID], '\n",
    "                   '[BuildingIdent],[Description],[Class],[TypeCode],[GlobalID])  '\n",
    "                   'values (?,?,?,?,?,?)',\n",
    "                   row['OBJECTID'],row['Building Identifier'],row['Description'],row['Classrooms'],row['TypeCode'],row['GlobalID'])\n",
    "cursor.commit()\n",
    "\n",
    "# https://tomaztsql.wordpress.com/2018/07/15/using-python-pandas-dataframe-to-read-and-insert-data-to-microsoft-sql-server/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executes insert into production table, from temp table, loading only new records\n",
    "cursor.execute('INSERT INTO [dbo].[src_prod](OBJECTID, '\n",
    "               'BuildingIdent,Description,Class,TypeCode,GlobalID) '  \n",
    "               'SELECT * FROM [dbo].[src_temp] UNION ' \n",
    "               'SELECT * FROM [dbo].[src_prod] EXCEPT ' \n",
    "               'SELECT * FROM [dbo].[src_temp] INTERSECT SELECT * FROM [dbo].[src_prod]')\n",
    "cursor.commit()\n",
    "\n",
    "# deletes temporary table\n",
    "#cursor.execute(delTEMP)\n",
    "cursor.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commits all previous executes, closes and deletes cursor and closes connection\n",
    "cursor.close()\n",
    "del cursor\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
