{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "## Script: AGOL_2_SQL.py\n",
    "## Author: Jeremy Mullins, Derek Morgan\n",
    "## Date:\n",
    "##\n",
    "## Description:\n",
    "##        This script is the test script for importing a AGOL feature layer into MS SQL as a table.\n",
    "##\n",
    "## Required prerequisites:\n",
    "##        - ArcGIS API for Python\n",
    "##            (https://developers.arcgis.com/python/)\n",
    "##\n",
    "##        - pyodbc Module\n",
    "##            (https://github.com/mkleehammer/pyodbc)\n",
    "##                to install after download, open Python command prompt and type the following:\n",
    "##                    -- conda install pyodbc  --\n",
    "##\n",
    "##        - MS ODBC Driver for SQL Server (v17)\n",
    "##            (https://docs.microsoft.com/en-us/sql/connect/odbc/download-odbc-driver-for-sql-server?view=sql-server-2017)\n",
    "##\n",
    "##        - Storing credentials locally\n",
    "##            (https://developers.arcgis.com/python/guide/working-with-different-authentication-schemes/)\n",
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary modules\n",
    "from arcgis.gis import GIS\n",
    "import os\n",
    "import configparser\n",
    "import pyodbc as sql\n",
    "import zipfile\n",
    "import arcpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The method described by Esri relies \n",
    "#on storing a an unencrypted config file named .arcgisprofile \n",
    "#on a \"home directory\". But where is the home directory\n",
    "#Note: if you are running a windows user that doesn't have access to \n",
    "#the windows profile, then you will not be able to use this method\n",
    "# os.environ['HOME']\n",
    "#Does the windows user current logged in have access?\n",
    "#Also, good idea to set the workspace:\n",
    "arcpy.env.workspace = \"W:\\src\"\n",
    "os.chdir('W:\\\\src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('W:/src/config_jm.ini')\n",
    "\n",
    "# assign config variables\n",
    "agolURL = config['AGOL']['URL']\n",
    "agolUSER = config['AGOL']['USER']\n",
    "agolPW = config['AGOL']['PW']\n",
    "iD = config['SCRIPT']['itemID']\n",
    "csvTITLE = config['SCRIPT']['csvTITLE']\n",
    "csvOUT = config['SCRIPT']['csvOUTPUT']\n",
    "zipLOC = config['SCRIPT']['zipLOC']\n",
    "zipEXT = config['SCRIPT']['zipExLOC']\n",
    "\n",
    "\n",
    "# sign into AGOL account\n",
    "gis = GIS(agolURL, agolUSER, agolPW)\n",
    "\n",
    "# get feature layer in question\n",
    "uwfBuildings = gis.content.get(iD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W:\\\\\\\\src\\\\uwfBuildings.zip'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export feature layer into CSV and save locally as ZIP file\n",
    "output_file = uwfBuildings.export(title=csvTITLE,\n",
    "                                   export_format=\"CSV\")\n",
    "output_file.download(csvOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unzip downloaded feature layer data\n",
    "zip_ref = zipfile.ZipFile(zipLOC, 'r')\n",
    "zip_ref.extractall(zipEXT)\n",
    "zip_ref.close()\n",
    "\n",
    "# remove excess files\n",
    "os.remove(zipLOC)\n",
    "output_file.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../auth_sql.config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-f204f888642a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#https://datatofish.com/how-to-connect-python-to-sql-server-using-pyodbc/\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msqlfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../auth_sql.config\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msqlfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpieces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msql_url\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mpieces\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../auth_sql.config'"
     ]
    }
   ],
   "source": [
    "#https://datatofish.com/how-to-connect-python-to-sql-server-using-pyodbc/\n",
    "sqlfile = open(\"../auth_sql.config\", \"r\")\n",
    "for line in sqlfile:\n",
    "    pieces = line.split(\",\")\n",
    "    sql_url  = pieces[0]\n",
    "    sql_user = pieces[1]\n",
    "    sql_pass = pieces[2]\n",
    "\n",
    "# import CSV into SQL database as view\n",
    "conn = sql.connect('Driver={SQL Server};'\n",
    "                      'Server='+sql_url+';'\n",
    "                      'Database=src_db;'\n",
    "                      'trusted_connection=yes;'\n",
    "                      'UID='+sql_user+';'\n",
    "                      'PWD='+sql_pass+';')\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('SELECT * FROM [dbo].[test_table]')\n",
    "\n",
    "for row in cursor:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
